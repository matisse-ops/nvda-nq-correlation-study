{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To help traders understand if NVDA offers a better risk-adjusted return than a diversified tech index.**\n",
    "\n",
    "The project explores the historical relationship between NVIDIA and NASDAQ 100 (QQQ). By analyzing rolling correlations and daily return distributions, we identify regime Shift periods where NVIDIA either decoupled from or led the broader technology market.\n",
    "\n",
    "Key Finding: While historically volatile, NVDA has shown a tightening correlation with the QQQ in recent quarters, suggesting its transition from a speculative asset to a primary driver of the index itself. As well NVDIA often moves independently from NASDAQ and is much more volatile on a macro scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA SOURCES:**\n",
    "\n",
    "**NVDA:** \n",
    "Daily price data was fetched from the yahoo finance API.\n",
    "**QQQ:** \n",
    "plit-adjusted daily price data was found on Kaggle.\n",
    "**Timeline:** \n",
    "Jan 01 2001 till 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions:\n",
    "\n",
    "#Box plot to show the spread of volatiliy in both assets\n",
    "def plot_volatility_spread(df, cols, title):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    sns.boxplot(df[cols])\n",
    "    \n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(\"Daily Percentage Change\")\n",
    "    plt.axhline(0, color='black', linestyle='--', alpha=0.3) \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "    \n",
    "#function to plot quarterly trend of QQQ and NVDA\n",
    "def plot_quarterly_trends(stats_df, asset_col, market_col, title=\"Quarterly Performance\"):\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    sns.lineplot(data=stats_df, x=stats_df.index, y=asset_col, label=asset_col, marker='o')\n",
    "    sns.lineplot(data=stats_df, x=stats_df.index, y=market_col, label=market_col, marker='s')\n",
    "    \n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(\"Total Quarterly Return (%)\")\n",
    "    plt.xlabel(\"Quarter\")\n",
    "    plt.xticks(rotation=90, fontsize=8) \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#pearsons correllation matrix\n",
    "def plot_correlation_matrix(df, cols):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    corr = df[cols].corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "    plt.title(\"Correlation Matrix: Daily Returns\")\n",
    "    plt.show()\n",
    "\n",
    "#Freuquency of Daily Returns Histogram Function   \n",
    "def plot_risk_shape(df, cols, title):\n",
    "    \n",
    "    plt.figure(figsize=(14,6))\n",
    "    for col in cols:\n",
    "        sns.histplot(df[col], kde=True, element=\"step\", label=col, alpha=0.5)\n",
    "    \n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Daily Return (%)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#Function to calculate quarterly correlation\n",
    "def quart_corr(df, asset_col, market_col):\n",
    "    # Grouping by the actual calendar quarter (Q-DEC means year ends in Dec)\n",
    "    q_corr = df.groupby(df['date'].dt.to_period('Q')).apply(\n",
    "    lambda x: x[asset_col].corr(x[market_col])\n",
    "    )\n",
    "    \n",
    "    return q_corr\n",
    "\n",
    "#Function to calculate rolling correlation\n",
    "def roll_corr(df, asset_col, market_col, window):\n",
    "    # Grouping by the actual calendar quarter (Q-DEC means year ends in Dec)\n",
    "    rolling_corr = df[asset_col].rolling(window).corr(df[market_col])\n",
    "    return rolling_corr\n",
    "\n",
    "\n",
    "#Function to calculated overall correlation\n",
    "def get_overall_corr(df, asset_col, market_col):\n",
    "    return df[asset_col].corr(df[market_col])\n",
    "    \n",
    "    \n",
    "\n",
    "#Regime bar plot function\n",
    "def plot_regime(df, asset_col, market_col, asset_name=\"Asset\", rwindow=60, title=\"Regime Analysis\"):\n",
    "    \n",
    "    #call quarterly correlation calculator function \n",
    "    rCorrelation = roll_corr(df, asset_col, market_col, 60)\n",
    "    baseline = get_overall_corr(df, asset_col, market_col)\n",
    "  \n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Plot the Quarterly Correlation as a Bar Chart\n",
    "    plt.plot(df['date'], rCorrelation, label=f'{rwindow}-Day Rolling Correlation', color=\"blue\")\n",
    "\n",
    "    # Plot the Overall Correlation as a solid Horizontal Line\n",
    "    plt.axhline(y=baseline, color='red', linestyle='--', linewidth=2, label=f'24-Year Average ({baseline:.2f})')\n",
    "\n",
    "\n",
    "    plt.grid(True, which='major', linestyle='-', alpha=0.7)\n",
    "    plt.grid(True, which='minor', linestyle=':', alpha=0.2)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(\"Correlation Coefficient\")\n",
    "    plt.xlabel(\"Years\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=(90), fontsize = 8)\n",
    "    plt.show()\n",
    "    \n",
    "#Regime bar plot function\n",
    "def plot_regime_bars(df, asset_col, market_col, asset_name=\"Asset\", market_name=\"Market\", title=\"graphTitle\", xTitle = \"xlabel\", yTitle=\"yTitle\"):\n",
    "    \n",
    "    #call quarterly correlation calculator function \n",
    "    quarterlyTable = quart_corr(df, asset_col, market_col)\n",
    "    \n",
    "    #Get the overall correlation value\n",
    "    overall_corr_val = df[asset_col].corr(df[market_col])\n",
    "    # 2. Create the plot\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Plot the Quarterly Correlation as a Bar Chart\n",
    "    quarterlyTable.plot(kind='bar', color='lightgray', alpha=0.7, label='Quarterly Regime')\n",
    "\n",
    "    # Plot the Overall Correlation as a solid Horizontal Line\n",
    "    plt.axhline(y=overall_corr_val, color='red', linestyle='--', linewidth=2, label=f'24-Year Average ({overall_corr_val:.2f})')\n",
    "\n",
    "    # Customizing the look\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel(yTitle)\n",
    "    plt.xlabel(xTitle)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=(90), fontsize = 8)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import NVDA ticker data\n",
    "\n",
    "try:\n",
    "    nvda_data = yf.download(\"NVDA\", start=\"2000-01-01\", auto_adjust=True, multi_level_index=False)\n",
    "    \n",
    "    if nvda_data.empty:\n",
    "        print(\"Warning: Downloaded dataframe is empty. Check ticker or connection.\")\n",
    "    else:\n",
    "        print(\"Data successfully downloaded.\")\n",
    "        print(nvda_data.head())\n",
    "except Exception as err:\n",
    "    print(f\"\\nError downloading: {err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening of columns to allows for analysis\n",
    "nvda_data.columns = nvda_data.columns.get_level_values(0)\n",
    "\n",
    "#Make date a column and not an index \n",
    "nvda_data = nvda_data.reset_index()\n",
    "\n",
    "nvda_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flattening Headers:**\n",
    "\n",
    "I reset the multi-level index from the API call to ensure the dataframe is \"flat\" and compatible with standard Pandas operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Inspect QQQ data\n",
    "\n",
    "QQQ_data = pd.read_csv(\"market_data/QQQ_split_adj.csv\")\n",
    "\n",
    "QQQ_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data clean up and changing NVDA column names to match QQQ and label prices\n",
    "\n",
    "nvda_data = nvda_data.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Close\": \"close_NVDA\",\n",
    "    \"High\": \"high_NVDA\",\n",
    "    \"Low\": \"low_NVDA\",\n",
    "    \"Open\": \"open_NVDA\",\n",
    "    \"Volume\": \"volume_NVDA\"\n",
    "    })\n",
    "\n",
    "#Rename QQQ price columns\n",
    "\n",
    "QQQ_data = QQQ_data.rename(columns={\n",
    "    \"date\": \"date\",\n",
    "    \"close\": \"close_QQQ\",\n",
    "    \"high\": \"high_QQQ\",\n",
    "    \"low\": \"low_QQQ\",\n",
    "    \"open\": \"open_QQQ\",\n",
    "    \"volume\": \"volume_QQQ\"\n",
    "    })\n",
    "\n",
    "#Enforce dateTime object casting\n",
    "nvda_data['date'] = pd.to_datetime(nvda_data['date'])\n",
    "QQQ_data['date'] = pd.to_datetime(QQQ_data['date'])\n",
    "\n",
    "#Filter QQQ data to start from 2000\n",
    "\n",
    "QQQ_data = QQQ_data[QQQ_data['date'] >= '2000-01-01']\n",
    "\n",
    "#Drop redundant columns\n",
    "\n",
    "QQQ_data = QQQ_data.drop([\"raw_close\", \"change_percent\", \"avg_vol_20d\"], axis = 1, errors = 'ignore')\n",
    "\n",
    "QQQ_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refactoring Table columns:**\n",
    "\n",
    "I renamed the column names to ensure both tables are compatible with each other. I also removed unimportant columns fron the QQQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove ghost header\n",
    "\n",
    "nvda_data.columns.name = None\n",
    "nvda_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table merging\n",
    "\n",
    "data_study = pd.merge(nvda_data, QQQ_data, on='date', how='inner')\n",
    "\n",
    "data_study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inner merge:**\n",
    "I joined the NVIDIA API data with the local QQQ CSV on the date column using an Inner Join. This ensures we only analyze days where data is present for both assets, automatically handling missing holiday data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_study.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Index\n",
    "\n",
    "data_study=data_study.reset_index(drop=True)\n",
    "data_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missng values (NaN)\n",
    "\n",
    "print(data_study.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates\n",
    "\n",
    "print(data_study.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check (NaN) and Duplicates:**\n",
    "\n",
    "Ensure that the new dataframe is free of null values and duplicate fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Data types\n",
    "\n",
    "data_study.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size Inspection\n",
    "data_study.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the percetage change between the current day close and previous close\n",
    "data_study['NVDA_pct'] = data_study['close_NVDA'].pct_change()\n",
    "data_study['QQQ_pct'] = data_study['close_QQQ'].pct_change()\n",
    "\n",
    "data_study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added 2 new columns for the daily percent chance of each asset (NVDA percentage change and QQQ percentage change). This was to ensure that the data is normalized and comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop initial empty row\n",
    "data_study = data_study.dropna()\n",
    "\n",
    "data_study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data clean up:**\n",
    "\n",
    "Calculating daily percentage change leaves the first row of data with a NULL value this the row needs to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot to show the spread of volatiliy in both assets\n",
    "\n",
    "plot_volatility_spread(data_study ,[\"NVDA_pct\", \"QQQ_pct\"], \"Distribution of daily return of NVDA and QQQ from 2000-2024\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Risk and Volatility Profile:**\n",
    "Before looking at correlations, we compare the daily return distributions to understand the risk profile of each asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "NVDA shows significantly wider whiskers and more frequent extreme outliers compared to the QQQ. This confirms that while they share a median return of ~0%, NVDA’s \"swings\" are much more violent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_study[['NVDA_pct', 'QQQ_pct']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe function confirmed the near 0% mean for both assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group daily returns by quarters\n",
    "q_percentent = data_study.groupby(data_study['date'].dt.to_period('Q')).apply(lambda g: g[['NVDA_pct','QQQ_pct']].sum())\n",
    "#change the quarter index to a string\n",
    "q_percentent.index = q_percentent.index.astype(str)\n",
    "\n",
    "#call quarterly trend plot\n",
    "plot_quarterly_trends(q_percentent, \"NVDA_pct\", \"QQQ_pct\", title=\"Quarterly Total Returns: NVDA vs QQQ (2000-2024)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total quarterly Returns:**\n",
    "Based on the daily volatily profile I wanted to investigate daily quarterly returns of each asset over a period of time to see when spikes in price occur and investigate possible underlying causes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "During the first quarter of 2000 NASDAQ(QQQ) was at a major peak along with NVDIA then collapsed during the 4th quarter. This coincides with the Dot-com bubble crash where by tech start-ups were heavily over-speculated in the late 90's then lost most of their valuation in the earlyer 2000's. Both asseets had another major crash during the #rd quarter of 20001 and this aligns with the September 9/11 attacks. The last quarter of 2001 proved to be the largest quarterly spike to the up-side for both assets with an increase of almost 2% attributed to a massive market recovery post 911 because of an increase in investor sentiment and FED rate cuts. This also aligned with the launch of the XBOX of which NVIDA was the sole provider for its GPU giving the company record breaaking profits in this period despite the Dot-com crash. Other drops in price coincide with the 2007–2009 recesion which saw stock prices plummet and the COVID-19 Pandemic Crash. Recently both assets have has positive quarterly percentage changes due to the AI-bubbles of which many companies in the NASDAQ have saw increase in stock valuations from including NVIDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Execution\n",
    "plot_correlation_matrix(data_study, [\"NVDA_pct\", \"QQQ_pct\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson Correlation Matrix: The Static Relationship:**\n",
    "\n",
    "Before diving into the time-based regime shifts we look at the Pearson Correlation Coefficient to determine the overall linear relationship between NVDA and QQQ across the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "We have a strong positive relationship, confirming that NVIDIA is a primary component of the Nasdaq's price action. For an investor, a correlation this high suggests that holding both NVDA and QQQ does not provide significant diversification benefit, as they tend to experience gains and losses at the same time. This would in turn leave your portfolio overexposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram to show the shape of the risk\n",
    "plot_risk_shape(data_study, [\"NVDA_pct\", \"QQQ_pct\"], \"Frequency of returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of the Distribution:**\n",
    "\n",
    "While summary statistics provide a numeric overview, a Histogram with Kernel Density Estimation allows us to visualize the probability distribution of daily returns. we are specifically looking for deviations from a normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "NVDA experiences far more frequent extreme daily moves (outliers) than the indeX, while QQQ is muc more stable with its distribution being tightly clustered and around 0 thus percentage changes are smaller and more predicatble making ot the better asset to invest in for long term returns. NVDA stretches much further along the x-axis, reaching beyond -0.3 (-30%) and +0.4 (+40%). This represents tail risk, meaning extreme price movements are much more frequent for an individual stock like NVDA than for a diversified index like QQQ. Both distributions peak very close to 0.0, which is typical for daily return data. This suggests that while the swings are large, the most frequent daily outcome for both is a relatively small change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proof that tails exist but are invisible\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TAIL EVENT FREQUENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "thresholds = [0.05, 0.10, 0.15, 0.20]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    nvda_count = len(data_study[abs(data_study['NVDA_pct']) > threshold])\n",
    "    qqq_count = len(data_study[abs(data_study['QQQ_pct']) > threshold])\n",
    "    \n",
    "    print(f\"\\nDays with moves > ±{threshold*100:.0f}%:\")\n",
    "    print(f\"  NVDA: {nvda_count:3d} days ({nvda_count/len(data_study)*100:.1f}%)\")\n",
    "    print(f\"  QQQ:  {qqq_count:3d} days ({qqq_count/len(data_study)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n These tail events exist but just rare (<<1% of days)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NVDA exhibits significantly fatter tails than the broader NASDAQ index (QQQ).**\n",
    "**Evidence:** \n",
    "While NVDA moves ±5% or more on 12.4% of trading days, QQQ only does so 1.9% of the time—a 6.4x difference. This gap widens at extreme thresholds: \n",
    "NVDA has experienced 16 days with ±20% moves over 24 years, while QQQ has never moved 20% in a single day.\n",
    "Implication: Standard correlation analysis assumes bivariate normality, which clearly doesn't hold here. This non-normality helps explain why our quarterly correlation varies so much during extreme NVDA events (which happen regularly), the relationship with QQQ can break down entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regime_bars(data_study, \"NVDA_pct\", \"QQQ_pct\", \"NVIDIA\", \"NASDAQ\", 'NVDA vs QQQ: Identifying Regime Deviations', 'Correlation Coefficient', 'Quarter') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quarterly Regime Blocks: Historical Deviations:**\n",
    "\n",
    "Finally, we group these correlations by quarter to create a Seasonality Map. This makes it easier to pinpoint specific historical events where the correlation fundamentally broke away from the long-term average. This approach allows us to see if the recent high correlation is an anomaly or a permanent shift in the market's structure due to NVDA's massive index weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "**Analysis: Historical Deviations & Seasonal Regimes**\n",
    "\n",
    "The quarterly bar chart provides a \"high-level\" map of the NVDA-QQQ relationship. By comparing each quarter's performance against the **24-year baseline (Red Dashed Line)**, we can observe several key financial phenomena:\n",
    "\n",
    "**Mean Reversion:** Historically, whenever the correlation \"decouples\" (bars fall significantly below the average), it tends to return to the mean in subsequent quarters. This suggests a strong, persistent fundamental link between the semiconductor sector and the broader tech index.\n",
    "**The \"Grey\" Gaps (Idiosyncratic Risk):** Quarters with very low bars represent periods where NVIDIA's price was driven by internal factors—such as product breakthroughs (original GeForce/Xbox launches) or specific earnings misses—independent of the general Nasdaq trend.\n",
    "**The AI Structural Shift (2023–Present):** There's high density of the bars in the most recent years. Unlike previous decades where correlation fluctuated wildly, the recent regime shows bars consistently pinned at or above the historical average.\n",
    "\n",
    "**Final Insight:** This confirms that the recent high correlation is not just a temporary \"spike\" but a **structural shift**. As NVDA’s market cap has grown, its mathematical weight in the QQQ has made decoupling much rarer, effectively turning NVDA into a primary engine of the index itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regime(data_study, \"NVDA_pct\", \"QQQ_pct\", rwindow=60, title=\"NVDA vs QQQ: 60-Day Rolling Correlation\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rolling Correlation (60 day):**\n",
    "We use a 60-Day Rolling Pearson Correlation to track the sync between the two assets. Static correlation matrices only tell us the average relationship over 24 years. To understand how the NVDA-QQQ relationship evolves during market crashes, tech booms, and the recent AI surge, we must look at how correlation changes over time.. The red dashed line represents the 24-year historical average baseline. The blue line is the 60-day rolling correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "Despite the high average, the correlation is highly unstable, frequently swinging between 0.2 (low relationship) and 0.9 (nearly identical movement).Looking at the data from 2020 to 2024, the correlation has frequently stayed above 0.8. This suggests that in the current AI-driven market, NVDA and the QQQ are more locked together than they were in the early 2000s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Final Conclusion**\n",
    "\n",
    "**Conclusion: Volatility and Risk Profile**\n",
    "Based on the Exploratory Data Analysis (EDA), we observed a significant divergence in the risk profiles of NVDA and QQQ:\n",
    "\n",
    "Heightened Volatility: NVDA displays a much wider distribution of daily returns, with frequent \"fat-tail\" events exceeding ±10%. In contrast, QQQ remains tightly clustered around a 0% mean return.\n",
    "\n",
    "Consistent Correlation: The long-term rolling correlation remains high at 0.63, suggesting that while NVDA is more volatile, it is still fundamentally tethered to the broader tech sector's movements.\n",
    "\n",
    "**Strategic Implications:**\n",
    "For a trader or investor, these findings suggest:\n",
    "\n",
    "Risk Management: Investors in NVDA must utilize wider stop-losses compared to QQQ to avoid being liquidated by standard daily market noise.\n",
    "\n",
    "Portfolio Concentration: Because the correlation has trended higher in recent years (often exceeding 0.8), holding both assets simultaneously provides less diversification benefit than historically expected.\n",
    "\n",
    "**Future Work**\n",
    "Next Steps for Research\n",
    "To further this project, I intend to:\n",
    "\n",
    "Perform a Beta Analysis to quantify exactly how much NVDA moves relative to every 1% move in the QQQ.\n",
    "\n",
    "Implement a Value at Risk (VaR) calculation to estimate the maximum potential loss over a 24-hour period at a 95% confidence level.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
